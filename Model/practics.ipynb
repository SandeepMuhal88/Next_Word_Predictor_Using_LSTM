{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "156437eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eff4be48",
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs= \"\"\"Hi my name is sandeep muhal.\n",
    "I am from ajmer.\n",
    "current i live in bikaner.\n",
    "and focus on my future.\n",
    "my background is technical.\n",
    "and my collage nane is bikaner technical university.\n",
    "that is my profile.\n",
    "and i know some programming language like java python c++ javascripts.\n",
    "i am a good person and i become a ai engineer.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1faf9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74a4c164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ae028d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acf4dc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([faqs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca80a9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'my': 1,\n",
       " 'i': 2,\n",
       " 'is': 3,\n",
       " 'and': 4,\n",
       " 'am': 5,\n",
       " 'bikaner': 6,\n",
       " 'technical': 7,\n",
       " 'a': 8,\n",
       " 'hi': 9,\n",
       " 'name': 10,\n",
       " 'sandeep': 11,\n",
       " 'muhal': 12,\n",
       " 'from': 13,\n",
       " 'ajmer': 14,\n",
       " 'current': 15,\n",
       " 'live': 16,\n",
       " 'in': 17,\n",
       " 'focus': 18,\n",
       " 'on': 19,\n",
       " 'future': 20,\n",
       " 'background': 21,\n",
       " 'collage': 22,\n",
       " 'nane': 23,\n",
       " 'university': 24,\n",
       " 'that': 25,\n",
       " 'profile': 26,\n",
       " 'know': 27,\n",
       " 'some': 28,\n",
       " 'programming': 29,\n",
       " 'language': 30,\n",
       " 'like': 31,\n",
       " 'java': 32,\n",
       " 'python': 33,\n",
       " 'c': 34,\n",
       " 'javascripts': 35,\n",
       " 'good': 36,\n",
       " 'person': 37,\n",
       " 'become': 38,\n",
       " 'ai': 39,\n",
       " 'engineer': 40}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f5fd8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence=[]\n",
    "for sentence in faqs.split('\\n'):\n",
    "    # print(sentence)\n",
    "    #  X=tokenizer.texts_to_sequences([sentence])[0]\n",
    "    token=tokenizer.texts_to_sequences([sentence])[0]\n",
    "    for i in range(1,len(token)):\n",
    "        input_sentence.append(token[:i+1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "885e0073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9, 1],\n",
       " [9, 1, 10],\n",
       " [9, 1, 10, 3],\n",
       " [9, 1, 10, 3, 11],\n",
       " [9, 1, 10, 3, 11, 12],\n",
       " [2, 5],\n",
       " [2, 5, 13],\n",
       " [2, 5, 13, 14],\n",
       " [15, 2],\n",
       " [15, 2, 16],\n",
       " [15, 2, 16, 17],\n",
       " [15, 2, 16, 17, 6],\n",
       " [4, 18],\n",
       " [4, 18, 19],\n",
       " [4, 18, 19, 1],\n",
       " [4, 18, 19, 1, 20],\n",
       " [1, 21],\n",
       " [1, 21, 3],\n",
       " [1, 21, 3, 7],\n",
       " [4, 1],\n",
       " [4, 1, 22],\n",
       " [4, 1, 22, 23],\n",
       " [4, 1, 22, 23, 3],\n",
       " [4, 1, 22, 23, 3, 6],\n",
       " [4, 1, 22, 23, 3, 6, 7],\n",
       " [4, 1, 22, 23, 3, 6, 7, 24],\n",
       " [25, 3],\n",
       " [25, 3, 1],\n",
       " [25, 3, 1, 26],\n",
       " [4, 2],\n",
       " [4, 2, 27],\n",
       " [4, 2, 27, 28],\n",
       " [4, 2, 27, 28, 29],\n",
       " [4, 2, 27, 28, 29, 30],\n",
       " [4, 2, 27, 28, 29, 30, 31],\n",
       " [4, 2, 27, 28, 29, 30, 31, 32],\n",
       " [4, 2, 27, 28, 29, 30, 31, 32, 33],\n",
       " [4, 2, 27, 28, 29, 30, 31, 32, 33, 34],\n",
       " [4, 2, 27, 28, 29, 30, 31, 32, 33, 34, 35],\n",
       " [2, 5],\n",
       " [2, 5, 8],\n",
       " [2, 5, 8, 36],\n",
       " [2, 5, 8, 36, 37],\n",
       " [2, 5, 8, 36, 37, 4],\n",
       " [2, 5, 8, 36, 37, 4, 2],\n",
       " [2, 5, 8, 36, 37, 4, 2, 38],\n",
       " [2, 5, 8, 36, 37, 4, 2, 38, 8],\n",
       " [2, 5, 8, 36, 37, 4, 2, 38, 8, 39],\n",
       " [2, 5, 8, 36, 37, 4, 2, 38, 8, 39, 40]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f92523c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=max([len(i) for i in input_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b74f788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "padded_input=pad_sequences(input_sentence,maxlen=max_len,padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48d3dbc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  9,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  9,  1, 10],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  9,  1, 10,  3],\n",
       "       [ 0,  0,  0,  0,  0,  0,  9,  1, 10,  3, 11],\n",
       "       [ 0,  0,  0,  0,  0,  9,  1, 10,  3, 11, 12],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  5],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  2,  5, 13],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  2,  5, 13, 14],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 15,  2],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0, 15,  2, 16],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 15,  2, 16, 17],\n",
       "       [ 0,  0,  0,  0,  0,  0, 15,  2, 16, 17,  6],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  4, 18],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  4, 18, 19],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  4, 18, 19,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  4, 18, 19,  1, 20],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 21],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  1, 21,  3],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  1, 21,  3,  7],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  4,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  4,  1, 22],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  4,  1, 22, 23],\n",
       "       [ 0,  0,  0,  0,  0,  0,  4,  1, 22, 23,  3],\n",
       "       [ 0,  0,  0,  0,  0,  4,  1, 22, 23,  3,  6],\n",
       "       [ 0,  0,  0,  0,  4,  1, 22, 23,  3,  6,  7],\n",
       "       [ 0,  0,  0,  4,  1, 22, 23,  3,  6,  7, 24],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 25,  3],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0, 25,  3,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 25,  3,  1, 26],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  4,  2],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  4,  2, 27],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  4,  2, 27, 28],\n",
       "       [ 0,  0,  0,  0,  0,  0,  4,  2, 27, 28, 29],\n",
       "       [ 0,  0,  0,  0,  0,  4,  2, 27, 28, 29, 30],\n",
       "       [ 0,  0,  0,  0,  4,  2, 27, 28, 29, 30, 31],\n",
       "       [ 0,  0,  0,  4,  2, 27, 28, 29, 30, 31, 32],\n",
       "       [ 0,  0,  4,  2, 27, 28, 29, 30, 31, 32, 33],\n",
       "       [ 0,  4,  2, 27, 28, 29, 30, 31, 32, 33, 34],\n",
       "       [ 4,  2, 27, 28, 29, 30, 31, 32, 33, 34, 35],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  5],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  2,  5,  8],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  2,  5,  8, 36],\n",
       "       [ 0,  0,  0,  0,  0,  0,  2,  5,  8, 36, 37],\n",
       "       [ 0,  0,  0,  0,  0,  2,  5,  8, 36, 37,  4],\n",
       "       [ 0,  0,  0,  0,  2,  5,  8, 36, 37,  4,  2],\n",
       "       [ 0,  0,  0,  2,  5,  8, 36, 37,  4,  2, 38],\n",
       "       [ 0,  0,  2,  5,  8, 36, 37,  4,  2, 38,  8],\n",
       "       [ 0,  2,  5,  8, 36, 37,  4,  2, 38,  8, 39],\n",
       "       [ 2,  5,  8, 36, 37,  4,  2, 38,  8, 39, 40]], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6214261",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=padded_input[:,:-1]\n",
    "y=padded_input[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9ecbb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  9],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  9,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  9,  1, 10],\n",
       "       [ 0,  0,  0,  0,  0,  0,  9,  1, 10,  3],\n",
       "       [ 0,  0,  0,  0,  0,  9,  1, 10,  3, 11],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  2],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  2,  5],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  2,  5, 13],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 15],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0, 15,  2],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 15,  2, 16],\n",
       "       [ 0,  0,  0,  0,  0,  0, 15,  2, 16, 17],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  4],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  4, 18],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  4, 18, 19],\n",
       "       [ 0,  0,  0,  0,  0,  0,  4, 18, 19,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  1, 21],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  1, 21,  3],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  4],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  4,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  4,  1, 22],\n",
       "       [ 0,  0,  0,  0,  0,  0,  4,  1, 22, 23],\n",
       "       [ 0,  0,  0,  0,  0,  4,  1, 22, 23,  3],\n",
       "       [ 0,  0,  0,  0,  4,  1, 22, 23,  3,  6],\n",
       "       [ 0,  0,  0,  4,  1, 22, 23,  3,  6,  7],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 25],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0, 25,  3],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 25,  3,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  4],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  4,  2],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  4,  2, 27],\n",
       "       [ 0,  0,  0,  0,  0,  0,  4,  2, 27, 28],\n",
       "       [ 0,  0,  0,  0,  0,  4,  2, 27, 28, 29],\n",
       "       [ 0,  0,  0,  0,  4,  2, 27, 28, 29, 30],\n",
       "       [ 0,  0,  0,  4,  2, 27, 28, 29, 30, 31],\n",
       "       [ 0,  0,  4,  2, 27, 28, 29, 30, 31, 32],\n",
       "       [ 0,  4,  2, 27, 28, 29, 30, 31, 32, 33],\n",
       "       [ 4,  2, 27, 28, 29, 30, 31, 32, 33, 34],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  2],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  2,  5],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  2,  5,  8],\n",
       "       [ 0,  0,  0,  0,  0,  0,  2,  5,  8, 36],\n",
       "       [ 0,  0,  0,  0,  0,  2,  5,  8, 36, 37],\n",
       "       [ 0,  0,  0,  0,  2,  5,  8, 36, 37,  4],\n",
       "       [ 0,  0,  0,  2,  5,  8, 36, 37,  4,  2],\n",
       "       [ 0,  0,  2,  5,  8, 36, 37,  4,  2, 38],\n",
       "       [ 0,  2,  5,  8, 36, 37,  4,  2, 38,  8],\n",
       "       [ 2,  5,  8, 36, 37,  4,  2, 38,  8, 39]], dtype=int32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db42c048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 10,  3, 11, 12,  5, 13, 14,  2, 16, 17,  6, 18, 19,  1, 20, 21,\n",
       "        3,  7,  1, 22, 23,  3,  6,  7, 24,  3,  1, 26,  2, 27, 28, 29, 30,\n",
       "       31, 32, 33, 34, 35,  5,  8, 36, 37,  4,  2, 38,  8, 39, 40],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e71031e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58b992c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a4e4abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y=to_categorical(y,num_classes=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "578ef6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfea9705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efd32f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 41)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91a3ce49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66c0b695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "496923d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding,LSTM,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f931d068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1 \n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51e0b013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Project-to-learn\\.machine\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "# model.add(Embedding(vocab_size,12,input_length=10))\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=30, input_length=10))\n",
    "model.add(LSTM(30))\n",
    "model.build(input_shape=(None,2))\n",
    "model.add(Dense(41,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aed39172",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a06cb32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,230</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,271</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m30\u001b[0m)          │         \u001b[38;5;34m1,230\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │         \u001b[38;5;34m7,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m)             │         \u001b[38;5;34m1,271\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,821</span> (38.36 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,821\u001b[0m (38.36 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,821</span> (38.36 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,821\u001b[0m (38.36 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b64635f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.0000e+00 - loss: 3.7167\n",
      "Epoch 2/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0000e+00 - loss: 3.7120\n",
      "Epoch 3/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0480 - loss: 3.7087\n",
      "Epoch 4/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0753 - loss: 3.7048\n",
      "Epoch 5/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0857 - loss: 3.7011\n",
      "Epoch 6/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0857 - loss: 3.6968\n",
      "Epoch 7/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0753 - loss: 3.6928\n",
      "Epoch 8/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0857 - loss: 3.6874\n",
      "Epoch 9/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0753 - loss: 3.6852\n",
      "Epoch 10/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0857 - loss: 3.6757\n",
      "Epoch 11/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0648 - loss: 3.6725\n",
      "Epoch 12/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.0648 - loss: 3.6659\n",
      "Epoch 13/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0857 - loss: 3.6516\n",
      "Epoch 14/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0961 - loss: 3.6322\n",
      "Epoch 15/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0961 - loss: 3.6131\n",
      "Epoch 16/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0857 - loss: 3.5973\n",
      "Epoch 17/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0961 - loss: 3.5704\n",
      "Epoch 18/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0753 - loss: 3.5676\n",
      "Epoch 19/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0857 - loss: 3.5389\n",
      "Epoch 20/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0857 - loss: 3.5302\n",
      "Epoch 21/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0753 - loss: 3.5113\n",
      "Epoch 22/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0857 - loss: 3.4765\n",
      "Epoch 23/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0889 - loss: 3.4910\n",
      "Epoch 24/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1097 - loss: 3.4619\n",
      "Epoch 25/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.1097 - loss: 3.4260\n",
      "Epoch 26/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.0993 - loss: 3.4483\n",
      "Epoch 27/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1201 - loss: 3.3776\n",
      "Epoch 28/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1097 - loss: 3.4019\n",
      "Epoch 29/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0993 - loss: 3.3834\n",
      "Epoch 30/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0889 - loss: 3.3982\n",
      "Epoch 31/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1097 - loss: 3.3719\n",
      "Epoch 32/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1337 - loss: 3.3619\n",
      "Epoch 33/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1233 - loss: 3.3428\n",
      "Epoch 34/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1129 - loss: 3.3587\n",
      "Epoch 35/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1129 - loss: 3.3100\n",
      "Epoch 36/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.1233 - loss: 3.2908\n",
      "Epoch 37/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1233 - loss: 3.2977\n",
      "Epoch 38/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0784 - loss: 3.3370\n",
      "Epoch 39/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1097 - loss: 3.2343\n",
      "Epoch 40/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1201 - loss: 3.2535\n",
      "Epoch 41/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0993 - loss: 3.2539\n",
      "Epoch 42/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0993 - loss: 3.2489\n",
      "Epoch 43/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1025 - loss: 3.2408\n",
      "Epoch 44/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1233 - loss: 3.2434\n",
      "Epoch 45/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1233 - loss: 3.1866 \n",
      "Epoch 46/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1233 - loss: 3.1978\n",
      "Epoch 47/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.1233 - loss: 3.1845\n",
      "Epoch 48/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.1233 - loss: 3.1585\n",
      "Epoch 49/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1337 - loss: 3.1455\n",
      "Epoch 50/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1233 - loss: 3.1571\n",
      "Epoch 51/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1233 - loss: 3.1270\n",
      "Epoch 52/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1129 - loss: 3.1072\n",
      "Epoch 53/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1025 - loss: 3.1450\n",
      "Epoch 54/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.1265 - loss: 3.0937\n",
      "Epoch 55/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1369 - loss: 3.1276\n",
      "Epoch 56/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1713 - loss: 3.0725\n",
      "Epoch 57/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1609 - loss: 3.0892\n",
      "Epoch 58/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1609 - loss: 3.0269\n",
      "Epoch 59/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1818 - loss: 2.9977\n",
      "Epoch 60/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1713 - loss: 3.0144\n",
      "Epoch 61/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1713 - loss: 2.9780\n",
      "Epoch 62/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1818 - loss: 3.0145\n",
      "Epoch 63/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1609 - loss: 2.9839\n",
      "Epoch 64/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.1609 - loss: 2.9741\n",
      "Epoch 65/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1609 - loss: 2.9154\n",
      "Epoch 66/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1401 - loss: 2.9483\n",
      "Epoch 67/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1745 - loss: 2.9058\n",
      "Epoch 68/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1641 - loss: 2.9226\n",
      "Epoch 69/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1745 - loss: 2.8765\n",
      "Epoch 70/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1609 - loss: 2.8869\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x20980e68d60>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6997efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step\n",
      "bikaner my\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "bikaner my my\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "bikaner my my my\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "bikaner my my my my\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "bikaner my my my my my\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "text = \"bikaner\"\n",
    "\n",
    "for i in range(5):\n",
    "  # tokenize\n",
    "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
    "  # padding\n",
    "  padded_token_text = pad_sequences([token_text], maxlen=56, padding='pre')\n",
    "  # predict\n",
    "  pos = np.argmax(model.predict(padded_token_text))\n",
    "\n",
    "  for word,index in tokenizer.word_index.items():\n",
    "    if index == pos:\n",
    "      text = text + \" \" + word\n",
    "      print(text)\n",
    "      time.sleep(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".machine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
