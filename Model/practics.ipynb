{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "156437eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eff4be48",
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs= \"\"\"Hi my name is sandeep muhal.\n",
    "I am from ajmer.\n",
    "current i live in bikaner.\n",
    "and focus on my future.\n",
    "my background is technical.\n",
    "and my collage nane is bikaner technical university.\n",
    "that is my profile.\n",
    "and i know some programming language like java python c++ javascripts.\n",
    "i am a good person and i become a ai engineer.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f1faf9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "74a4c164",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4ae028d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "acf4dc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([faqs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ca80a9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'my': 1,\n",
       " 'i': 2,\n",
       " 'is': 3,\n",
       " 'and': 4,\n",
       " 'am': 5,\n",
       " 'bikaner': 6,\n",
       " 'technical': 7,\n",
       " 'a': 8,\n",
       " 'hi': 9,\n",
       " 'name': 10,\n",
       " 'sandeep': 11,\n",
       " 'muhal': 12,\n",
       " 'from': 13,\n",
       " 'ajmer': 14,\n",
       " 'current': 15,\n",
       " 'live': 16,\n",
       " 'in': 17,\n",
       " 'focus': 18,\n",
       " 'on': 19,\n",
       " 'future': 20,\n",
       " 'background': 21,\n",
       " 'collage': 22,\n",
       " 'nane': 23,\n",
       " 'university': 24,\n",
       " 'that': 25,\n",
       " 'profile': 26,\n",
       " 'know': 27,\n",
       " 'some': 28,\n",
       " 'programming': 29,\n",
       " 'language': 30,\n",
       " 'like': 31,\n",
       " 'java': 32,\n",
       " 'python': 33,\n",
       " 'c': 34,\n",
       " 'javascripts': 35,\n",
       " 'good': 36,\n",
       " 'person': 37,\n",
       " 'become': 38,\n",
       " 'ai': 39,\n",
       " 'engineer': 40}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4f5fd8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence=[]\n",
    "for sentence in faqs.split('\\n'):\n",
    "    # print(sentence)\n",
    "    #  X=tokenizer.texts_to_sequences([sentence])[0]\n",
    "    token=tokenizer.texts_to_sequences([sentence])[0]\n",
    "    for i in range(1,len(token)):\n",
    "        input_sentence.append(token[:i+1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "885e0073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9, 1],\n",
       " [9, 1, 10],\n",
       " [9, 1, 10, 3],\n",
       " [9, 1, 10, 3, 11],\n",
       " [9, 1, 10, 3, 11, 12],\n",
       " [2, 5],\n",
       " [2, 5, 13],\n",
       " [2, 5, 13, 14],\n",
       " [15, 2],\n",
       " [15, 2, 16],\n",
       " [15, 2, 16, 17],\n",
       " [15, 2, 16, 17, 6],\n",
       " [4, 18],\n",
       " [4, 18, 19],\n",
       " [4, 18, 19, 1],\n",
       " [4, 18, 19, 1, 20],\n",
       " [1, 21],\n",
       " [1, 21, 3],\n",
       " [1, 21, 3, 7],\n",
       " [4, 1],\n",
       " [4, 1, 22],\n",
       " [4, 1, 22, 23],\n",
       " [4, 1, 22, 23, 3],\n",
       " [4, 1, 22, 23, 3, 6],\n",
       " [4, 1, 22, 23, 3, 6, 7],\n",
       " [4, 1, 22, 23, 3, 6, 7, 24],\n",
       " [25, 3],\n",
       " [25, 3, 1],\n",
       " [25, 3, 1, 26],\n",
       " [4, 2],\n",
       " [4, 2, 27],\n",
       " [4, 2, 27, 28],\n",
       " [4, 2, 27, 28, 29],\n",
       " [4, 2, 27, 28, 29, 30],\n",
       " [4, 2, 27, 28, 29, 30, 31],\n",
       " [4, 2, 27, 28, 29, 30, 31, 32],\n",
       " [4, 2, 27, 28, 29, 30, 31, 32, 33],\n",
       " [4, 2, 27, 28, 29, 30, 31, 32, 33, 34],\n",
       " [4, 2, 27, 28, 29, 30, 31, 32, 33, 34, 35],\n",
       " [2, 5],\n",
       " [2, 5, 8],\n",
       " [2, 5, 8, 36],\n",
       " [2, 5, 8, 36, 37],\n",
       " [2, 5, 8, 36, 37, 4],\n",
       " [2, 5, 8, 36, 37, 4, 2],\n",
       " [2, 5, 8, 36, 37, 4, 2, 38],\n",
       " [2, 5, 8, 36, 37, 4, 2, 38, 8],\n",
       " [2, 5, 8, 36, 37, 4, 2, 38, 8, 39],\n",
       " [2, 5, 8, 36, 37, 4, 2, 38, 8, 39, 40]]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f92523c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=max([len(i) for i in input_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4b74f788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "padded_input=pad_sequences(input_sentence,maxlen=max_len,padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "48d3dbc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  9,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  9,  1, 10],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  9,  1, 10,  3],\n",
       "       [ 0,  0,  0,  0,  0,  0,  9,  1, 10,  3, 11],\n",
       "       [ 0,  0,  0,  0,  0,  9,  1, 10,  3, 11, 12],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  5],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  2,  5, 13],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  2,  5, 13, 14],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 15,  2],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0, 15,  2, 16],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 15,  2, 16, 17],\n",
       "       [ 0,  0,  0,  0,  0,  0, 15,  2, 16, 17,  6],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  4, 18],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  4, 18, 19],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  4, 18, 19,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  4, 18, 19,  1, 20],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 21],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  1, 21,  3],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  1, 21,  3,  7],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  4,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  4,  1, 22],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  4,  1, 22, 23],\n",
       "       [ 0,  0,  0,  0,  0,  0,  4,  1, 22, 23,  3],\n",
       "       [ 0,  0,  0,  0,  0,  4,  1, 22, 23,  3,  6],\n",
       "       [ 0,  0,  0,  0,  4,  1, 22, 23,  3,  6,  7],\n",
       "       [ 0,  0,  0,  4,  1, 22, 23,  3,  6,  7, 24],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 25,  3],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0, 25,  3,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 25,  3,  1, 26],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  4,  2],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  4,  2, 27],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  4,  2, 27, 28],\n",
       "       [ 0,  0,  0,  0,  0,  0,  4,  2, 27, 28, 29],\n",
       "       [ 0,  0,  0,  0,  0,  4,  2, 27, 28, 29, 30],\n",
       "       [ 0,  0,  0,  0,  4,  2, 27, 28, 29, 30, 31],\n",
       "       [ 0,  0,  0,  4,  2, 27, 28, 29, 30, 31, 32],\n",
       "       [ 0,  0,  4,  2, 27, 28, 29, 30, 31, 32, 33],\n",
       "       [ 0,  4,  2, 27, 28, 29, 30, 31, 32, 33, 34],\n",
       "       [ 4,  2, 27, 28, 29, 30, 31, 32, 33, 34, 35],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  2,  5],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  2,  5,  8],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  2,  5,  8, 36],\n",
       "       [ 0,  0,  0,  0,  0,  0,  2,  5,  8, 36, 37],\n",
       "       [ 0,  0,  0,  0,  0,  2,  5,  8, 36, 37,  4],\n",
       "       [ 0,  0,  0,  0,  2,  5,  8, 36, 37,  4,  2],\n",
       "       [ 0,  0,  0,  2,  5,  8, 36, 37,  4,  2, 38],\n",
       "       [ 0,  0,  2,  5,  8, 36, 37,  4,  2, 38,  8],\n",
       "       [ 0,  2,  5,  8, 36, 37,  4,  2, 38,  8, 39],\n",
       "       [ 2,  5,  8, 36, 37,  4,  2, 38,  8, 39, 40]], dtype=int32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d6214261",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=padded_input[:,:-1]\n",
    "y=padded_input[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d9ecbb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  9],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  9,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  9,  1, 10],\n",
       "       [ 0,  0,  0,  0,  0,  0,  9,  1, 10,  3],\n",
       "       [ 0,  0,  0,  0,  0,  9,  1, 10,  3, 11],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  2],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  2,  5],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  2,  5, 13],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 15],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0, 15,  2],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 15,  2, 16],\n",
       "       [ 0,  0,  0,  0,  0,  0, 15,  2, 16, 17],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  4],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  4, 18],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  4, 18, 19],\n",
       "       [ 0,  0,  0,  0,  0,  0,  4, 18, 19,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  1, 21],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  1, 21,  3],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  4],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  4,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  4,  1, 22],\n",
       "       [ 0,  0,  0,  0,  0,  0,  4,  1, 22, 23],\n",
       "       [ 0,  0,  0,  0,  0,  4,  1, 22, 23,  3],\n",
       "       [ 0,  0,  0,  0,  4,  1, 22, 23,  3,  6],\n",
       "       [ 0,  0,  0,  4,  1, 22, 23,  3,  6,  7],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 25],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0, 25,  3],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 25,  3,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  4],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  4,  2],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  4,  2, 27],\n",
       "       [ 0,  0,  0,  0,  0,  0,  4,  2, 27, 28],\n",
       "       [ 0,  0,  0,  0,  0,  4,  2, 27, 28, 29],\n",
       "       [ 0,  0,  0,  0,  4,  2, 27, 28, 29, 30],\n",
       "       [ 0,  0,  0,  4,  2, 27, 28, 29, 30, 31],\n",
       "       [ 0,  0,  4,  2, 27, 28, 29, 30, 31, 32],\n",
       "       [ 0,  4,  2, 27, 28, 29, 30, 31, 32, 33],\n",
       "       [ 4,  2, 27, 28, 29, 30, 31, 32, 33, 34],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  2],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  2,  5],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  2,  5,  8],\n",
       "       [ 0,  0,  0,  0,  0,  0,  2,  5,  8, 36],\n",
       "       [ 0,  0,  0,  0,  0,  2,  5,  8, 36, 37],\n",
       "       [ 0,  0,  0,  0,  2,  5,  8, 36, 37,  4],\n",
       "       [ 0,  0,  0,  2,  5,  8, 36, 37,  4,  2],\n",
       "       [ 0,  0,  2,  5,  8, 36, 37,  4,  2, 38],\n",
       "       [ 0,  2,  5,  8, 36, 37,  4,  2, 38,  8],\n",
       "       [ 2,  5,  8, 36, 37,  4,  2, 38,  8, 39]], dtype=int32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "db42c048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 10,  3, 11, 12,  5, 13, 14,  2, 16, 17,  6, 18, 19,  1, 20, 21,\n",
       "        3,  7,  1, 22, 23,  3,  6,  7, 24,  3,  1, 26,  2, 27, 28, 29, 30,\n",
       "       31, 32, 33, 34, 35,  5,  8, 36, 37,  4,  2, 38,  8, 39, 40],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e71031e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 10)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "58b992c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1a4e4abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y=to_categorical(y,num_classes=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "578ef6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bfea9705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "efd32f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 41)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "91a3ce49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "66c0b695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "496923d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding,LSTM,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f931d068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1 \n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "51e0b013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Project-to-learn\\.machine\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "# model.add(Embedding(vocab_size,12,input_length=10))\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=30, input_length=10))\n",
    "model.add(LSTM(30))\n",
    "model.build(input_shape=(None,2))\n",
    "model.add(Dense(41,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "aed39172",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2a06cb32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_15\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_15\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)          │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,230</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,271</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_14 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m30\u001b[0m)          │         \u001b[38;5;34m1,230\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_14 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │         \u001b[38;5;34m7,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m)             │         \u001b[38;5;34m1,271\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,821</span> (38.36 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,821\u001b[0m (38.36 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,821</span> (38.36 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,821\u001b[0m (38.36 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7b64635f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4284 - loss: 2.3404\n",
      "Epoch 2/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3939 - loss: 2.3455\n",
      "Epoch 3/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3971 - loss: 2.3434\n",
      "Epoch 4/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4420 - loss: 2.2887\n",
      "Epoch 5/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3835 - loss: 2.2738\n",
      "Epoch 6/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4420 - loss: 2.2389\n",
      "Epoch 7/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4211 - loss: 2.2674 \n",
      "Epoch 8/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4243 - loss: 2.2580\n",
      "Epoch 9/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4347 - loss: 2.2447\n",
      "Epoch 10/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4452 - loss: 2.1796\n",
      "Epoch 11/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4556 - loss: 2.1492\n",
      "Epoch 12/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4556 - loss: 2.1607 \n",
      "Epoch 13/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4003 - loss: 2.1803 \n",
      "Epoch 14/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4452 - loss: 2.1339\n",
      "Epoch 15/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4556 - loss: 2.0853\n",
      "Epoch 16/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4900 - loss: 2.0682\n",
      "Epoch 17/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4796 - loss: 2.0429\n",
      "Epoch 18/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4483 - loss: 2.0668\n",
      "Epoch 19/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4515 - loss: 2.1193 \n",
      "Epoch 20/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4588 - loss: 2.0212\n",
      "Epoch 21/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4796 - loss: 2.0078\n",
      "Epoch 22/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4692 - loss: 2.0053\n",
      "Epoch 23/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4483 - loss: 2.0195\n",
      "Epoch 24/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4588 - loss: 1.9836\n",
      "Epoch 25/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4515 - loss: 2.0077\n",
      "Epoch 26/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5172 - loss: 1.9496\n",
      "Epoch 27/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5172 - loss: 1.9173\n",
      "Epoch 28/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5276 - loss: 1.8968\n",
      "Epoch 29/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5172 - loss: 1.9081\n",
      "Epoch 30/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4964 - loss: 1.9025\n",
      "Epoch 31/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5100 - loss: 1.9052\n",
      "Epoch 32/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4996 - loss: 1.8989\n",
      "Epoch 33/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5412 - loss: 1.8208\n",
      "Epoch 34/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5412 - loss: 1.8375\n",
      "Epoch 35/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5517 - loss: 1.8195\n",
      "Epoch 36/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5548 - loss: 1.8264\n",
      "Epoch 37/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5653 - loss: 1.7771\n",
      "Epoch 38/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5925 - loss: 1.7974\n",
      "Epoch 39/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.5789 - loss: 1.7701\n",
      "Epoch 40/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5685 - loss: 1.7779\n",
      "Epoch 41/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5789 - loss: 1.7204\n",
      "Epoch 42/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5997 - loss: 1.7068\n",
      "Epoch 43/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5580 - loss: 1.7372\n",
      "Epoch 44/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5821 - loss: 1.7347\n",
      "Epoch 45/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5997 - loss: 1.6774\n",
      "Epoch 46/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5925 - loss: 1.6963 \n",
      "Epoch 47/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5789 - loss: 1.6742\n",
      "Epoch 48/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5789 - loss: 1.6828\n",
      "Epoch 49/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5580 - loss: 1.6900\n",
      "Epoch 50/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5685 - loss: 1.6705\n",
      "Epoch 51/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5580 - loss: 1.6616\n",
      "Epoch 52/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6237 - loss: 1.5870\n",
      "Epoch 53/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6165 - loss: 1.6336\n",
      "Epoch 54/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5957 - loss: 1.6311\n",
      "Epoch 55/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6269 - loss: 1.5844\n",
      "Epoch 56/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5957 - loss: 1.6219\n",
      "Epoch 57/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6405 - loss: 1.5506\n",
      "Epoch 58/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7230 - loss: 1.5283\n",
      "Epoch 59/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6781 - loss: 1.5264\n",
      "Epoch 60/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6886 - loss: 1.5422\n",
      "Epoch 61/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6813 - loss: 1.5595\n",
      "Epoch 62/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6501 - loss: 1.6134\n",
      "Epoch 63/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6709 - loss: 1.5487\n",
      "Epoch 64/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6605 - loss: 1.5490\n",
      "Epoch 65/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7022 - loss: 1.5056\n",
      "Epoch 66/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6677 - loss: 1.4848\n",
      "Epoch 67/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6605 - loss: 1.5298\n",
      "Epoch 68/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6573 - loss: 1.5123\n",
      "Epoch 69/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7054 - loss: 1.4850\n",
      "Epoch 70/70\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7054 - loss: 1.4457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x19ae1b5ce50>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e6997efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "bikaner my\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "bikaner my my\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "bikaner my my is\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "bikaner my my is is\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "bikaner my my is is technical\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "text = \"bikaner\"\n",
    "\n",
    "for i in range(5):\n",
    "  # tokenize\n",
    "  token_text = tokenizer.texts_to_sequences([text])[0]\n",
    "  # padding\n",
    "  padded_token_text = pad_sequences([token_text], maxlen=56, padding='pre')\n",
    "  # predict\n",
    "  pos = np.argmax(model.predict(padded_token_text))\n",
    "\n",
    "  for word,index in tokenizer.word_index.items():\n",
    "    if index == pos:\n",
    "      text = text + \" \" + word\n",
    "      print(text)\n",
    "      time.sleep(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".machine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
